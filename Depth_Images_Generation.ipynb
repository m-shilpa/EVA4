{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Depth_imgs_generation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5725dc476d4a47cea846f55a56828755": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_286f10453aec487aa8183f6ba949027e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5b223155c6da4db5940842cef65b6649",
              "IPY_MODEL_4a6e0881b71941e1badc66998f25388a"
            ]
          }
        },
        "286f10453aec487aa8183f6ba949027e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5b223155c6da4db5940842cef65b6649": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d3b3b5bbf38e4e4da34271a098aab337",
            "_dom_classes": [],
            "description": "Loading from 159501 images: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 500,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 500,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_161c83b6068b4d3483f755385479c2f1"
          }
        },
        "4a6e0881b71941e1badc66998f25388a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8eb2c34feead4c3d96eebab4223f716c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 500/500 [00:10&lt;00:00, 49.38it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_595dc5e2d6af424f878267df886614dd"
          }
        },
        "d3b3b5bbf38e4e4da34271a098aab337": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "161c83b6068b4d3483f755385479c2f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8eb2c34feead4c3d96eebab4223f716c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "595dc5e2d6af424f878267df886614dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mshilpaa/EVA4/blob/master/Depth_Images_Generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMHwyDvnnQ0J",
        "colab_type": "code",
        "outputId": "56188ac0-c1b3-41cc-f7da-4cf34be473d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jLUKF8anXcQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "import random\n",
        "import copy\n",
        "import PIL"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acVt9UICZFlp",
        "colab_type": "code",
        "outputId": "f8aef643-ba19-4314-fbf9-f4f1898b1bfe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# To extract a  file, this is for depth images. After zipping. Only to read images\n",
        "\n",
        "#To import zip file\n",
        "from zipfile import ZipFile \n",
        "  \n",
        "# specifying the zip file name \n",
        "file_name = \"/content/gdrive/My Drive/dataset_Part2.zip\"\n",
        "  \n",
        "# opening the zip file in READ mode \n",
        "with ZipFile(file_name, 'r') as zip: \n",
        "    # printing all the contents of the zip file \n",
        "    #zip.printdir() \n",
        "  \n",
        "    # extracting all the files \n",
        "    print('Extracting all the files now...') \n",
        "    zip.extractall() \n",
        "    print('Done!') "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting all the files now...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOmgE1gOcVm2",
        "colab_type": "code",
        "outputId": "9b85c9d2-af64-4e03-9333-4da213d8f68d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "!ls "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RZNpO47cw8E",
        "colab_type": "code",
        "outputId": "60311ed9-c3d3-472d-a146-92af1e98d9b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "!ls Overlay2/Fg-Bg | wc -l"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "80000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DsuXz1hFdWxt",
        "colab_type": "code",
        "outputId": "64af4929-18a3-40da-c890-7d0ed484bc88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "!ls Overlay2/Fg-Bg-Mask | wc -l"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "80000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pC9-02VpTDwr",
        "colab_type": "code",
        "outputId": "dc75f478-f878-49ac-c059-6d669ea5fa48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "!git clone https://github.com/mshilpaa/DenseDepth"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'DepthModel'...\n",
            "remote: Enumerating objects: 245, done.\u001b[K\n",
            "remote: Counting objects:   0% (1/245)\u001b[K\rremote: Counting objects:   1% (3/245)\u001b[K\rremote: Counting objects:   2% (5/245)\u001b[K\rremote: Counting objects:   3% (8/245)\u001b[K\rremote: Counting objects:   4% (10/245)\u001b[K\rremote: Counting objects:   5% (13/245)\u001b[K\rremote: Counting objects:   6% (15/245)\u001b[K\rremote: Counting objects:   7% (18/245)\u001b[K\rremote: Counting objects:   8% (20/245)\u001b[K\rremote: Counting objects:   9% (23/245)\u001b[K\rremote: Counting objects:  10% (25/245)\u001b[K\rremote: Counting objects:  11% (27/245)\u001b[K\rremote: Counting objects:  12% (30/245)\u001b[K\rremote: Counting objects:  13% (32/245)\u001b[K\rremote: Counting objects:  14% (35/245)\u001b[K\rremote: Counting objects:  15% (37/245)\u001b[K\rremote: Counting objects:  16% (40/245)\u001b[K\rremote: Counting objects:  17% (42/245)\u001b[K\rremote: Counting objects:  18% (45/245)\u001b[K\rremote: Counting objects:  19% (47/245)\u001b[K\rremote: Counting objects:  20% (49/245)\u001b[K\rremote: Counting objects:  21% (52/245)\u001b[K\rremote: Counting objects:  22% (54/245)\u001b[K\rremote: Counting objects:  23% (57/245)\u001b[K\rremote: Counting objects:  24% (59/245)\u001b[K\rremote: Counting objects:  25% (62/245)\u001b[K\rremote: Counting objects:  26% (64/245)\u001b[K\rremote: Counting objects:  27% (67/245)\u001b[K\rremote: Counting objects:  28% (69/245)\u001b[K\rremote: Counting objects:  29% (72/245)\u001b[K\rremote: Counting objects:  30% (74/245)\u001b[K\rremote: Counting objects:  31% (76/245)\u001b[K\rremote: Counting objects:  32% (79/245)\u001b[K\rremote: Counting objects:  33% (81/245)\u001b[K\rremote: Counting objects:  34% (84/245)\u001b[K\rremote: Counting objects:  35% (86/245)\u001b[K\rremote: Counting objects:  36% (89/245)\u001b[K\rremote: Counting objects:  37% (91/245)\u001b[K\rremote: Counting objects:  38% (94/245)\u001b[K\rremote: Counting objects:  39% (96/245)\u001b[K\rremote: Counting objects:  40% (98/245)\u001b[K\rremote: Counting objects:  41% (101/245)\rremote: Counting objects:  42% (103/245)\u001b[K\rremote: Counting objects:  43% (106/245)\u001b[K\rremote: Counting objects:  44% (108/245)\u001b[K\rremote: Counting objects:  45% (111/245)\u001b[K\rremote: Counting objects:  46% (113/245)\u001b[K\rremote: Counting objects:  47% (116/245)\u001b[K\rremote: Counting objects:  48% (118/245)\u001b[K\rremote: Counting objects:  49% (121/245)\u001b[K\rremote: Counting objects:  50% (123/245)\u001b[K\rremote: Counting objects:  51% (125/245)\u001b[K\rremote: Counting objects:  52% (128/245)\u001b[K\rremote: Counting objects:  53% (130/245)\u001b[K\rremote: Counting objects:  54% (133/245)\u001b[K\rremote: Counting objects:  55% (135/245)\u001b[K\rremote: Counting objects:  56% (138/245)\u001b[K\rremote: Counting objects:  57% (140/245)\u001b[K\rremote: Counting objects:  58% (143/245)\u001b[K\rremote: Counting objects:  59% (145/245)\u001b[K\rremote: Counting objects:  60% (147/245)\u001b[K\rremote: Counting objects:  61% (150/245)\u001b[K\rremote: Counting objects:  62% (152/245)\u001b[K\rremote: Counting objects:  63% (155/245)\u001b[K\rremote: Counting objects:  64% (157/245)\u001b[K\rremote: Counting objects:  65% (160/245)\u001b[K\rremote: Counting objects:  66% (162/245)\u001b[K\rremote: Counting objects:  67% (165/245)\u001b[K\rremote: Counting objects:  68% (167/245)\u001b[K\rremote: Counting objects:  69% (170/245)\u001b[K\rremote: Counting objects:  70% (172/245)\u001b[K\rremote: Counting objects:  71% (174/245)\u001b[K\rremote: Counting objects:  72% (177/245)\u001b[K\rremote: Counting objects:  73% (179/245)\u001b[K\rremote: Counting objects:  74% (182/245)\u001b[K\rremote: Counting objects:  75% (184/245)\u001b[K\rremote: Counting objects:  76% (187/245)\u001b[K\rremote: Counting objects:  77% (189/245)\u001b[K\rremote: Counting objects:  78% (192/245)\u001b[K\rremote: Counting objects:  79% (194/245)\u001b[K\rremote: Counting objects:  80% (196/245)\u001b[K\rremote: Counting objects:  81% (199/245)\u001b[K\rremote: Counting objects:  82% (201/245)\u001b[K\rremote: Counting objects:  83% (204/245)\u001b[K\rremote: Counting objects:  84% (206/245)\u001b[K\rremote: Counting objects:  85% (209/245)\u001b[K\rremote: Counting objects:  86% (211/245)\u001b[K\rremote: Counting objects:  87% (214/245)\u001b[K\rremote: Counting objects:  88% (216/245)\u001b[K\rremote: Counting objects:  89% (219/245)\u001b[K\rremote: Counting objects:  90% (221/245)\u001b[K\rremote: Counting objects:  91% (223/245)\u001b[K\rremote: Counting objects:  92% (226/245)\u001b[K\rremote: Counting objects:  93% (228/245)\u001b[K\rremote: Counting objects:  94% (231/245)\u001b[K\rremote: Counting objects:  95% (233/245)\u001b[K\rremote: Counting objects:  96% (236/245)\u001b[K\rremote: Counting objects:  97% (238/245)\u001b[K\rremote: Counting objects:  98% (241/245)\u001b[K\rremote: Counting objects:  99% (243/245)\u001b[K\rremote: Counting objects: 100% (245/245)\u001b[K\rremote: Counting objects: 100% (245/245), done.\u001b[K\n",
            "remote: Compressing objects:   0% (1/117)\u001b[K\rremote: Compressing objects:   1% (2/117)\u001b[K\rremote: Compressing objects:   2% (3/117)\u001b[K\rremote: Compressing objects:   3% (4/117)\u001b[K\rremote: Compressing objects:   4% (5/117)\u001b[K\rremote: Compressing objects:   5% (6/117)\u001b[K\rremote: Compressing objects:   6% (8/117)\u001b[K\rremote: Compressing objects:   7% (9/117)\u001b[K\rremote: Compressing objects:   8% (10/117)\u001b[K\rremote: Compressing objects:   9% (11/117)\u001b[K\rremote: Compressing objects:  10% (12/117)\u001b[K\rremote: Compressing objects:  11% (13/117)\u001b[K\rremote: Compressing objects:  12% (15/117)\u001b[K\rremote: Compressing objects:  13% (16/117)\u001b[K\rremote: Compressing objects:  14% (17/117)\u001b[K\rremote: Compressing objects:  15% (18/117)\u001b[K\rremote: Compressing objects:  16% (19/117)\u001b[K\rremote: Compressing objects:  17% (20/117)\u001b[K\rremote: Compressing objects:  18% (22/117)\u001b[K\rremote: Compressing objects:  19% (23/117)\u001b[K\rremote: Compressing objects:  20% (24/117)\u001b[K\rremote: Compressing objects:  21% (25/117)\u001b[K\rremote: Compressing objects:  22% (26/117)\u001b[K\rremote: Compressing objects:  23% (27/117)\u001b[K\rremote: Compressing objects:  24% (29/117)\u001b[K\rremote: Compressing objects:  25% (30/117)\u001b[K\rremote: Compressing objects:  26% (31/117)\u001b[K\rremote: Compressing objects:  27% (32/117)\u001b[K\rremote: Compressing objects:  28% (33/117)\u001b[K\rremote: Compressing objects:  29% (34/117)\u001b[K\rremote: Compressing objects:  30% (36/117)\u001b[K\rremote: Compressing objects:  31% (37/117)\u001b[K\rremote: Compressing objects:  32% (38/117)\u001b[K\rremote: Compressing objects:  33% (39/117)\u001b[K\rremote: Compressing objects:  34% (40/117)\u001b[K\rremote: Compressing objects:  35% (41/117)\u001b[K\rremote: Compressing objects:  36% (43/117)\u001b[K\rremote: Compressing objects:  37% (44/117)\u001b[K\rremote: Compressing objects:  38% (45/117)\u001b[K\rremote: Compressing objects:  39% (46/117)\u001b[K\rremote: Compressing objects:  40% (47/117)\u001b[K\rremote: Compressing objects:  41% (48/117)\u001b[K\rremote: Compressing objects:  42% (50/117)\u001b[K\rremote: Compressing objects:  43% (51/117)\u001b[K\rremote: Compressing objects:  44% (52/117)\u001b[K\rremote: Compressing objects:  45% (53/117)\u001b[K\rremote: Compressing objects:  46% (54/117)\u001b[K\rremote: Compressing objects:  47% (55/117)\u001b[K\rremote: Compressing objects:  48% (57/117)\u001b[K\rremote: Compressing objects:  49% (58/117)\u001b[K\rremote: Compressing objects:  50% (59/117)\u001b[K\rremote: Compressing objects:  51% (60/117)\u001b[K\rremote: Compressing objects:  52% (61/117)\u001b[K\rremote: Compressing objects:  53% (63/117)\u001b[K\rremote: Compressing objects:  54% (64/117)\u001b[K\rremote: Compressing objects:  55% (65/117)\u001b[K\rremote: Compressing objects:  56% (66/117)\u001b[K\rremote: Compressing objects:  57% (67/117)\u001b[K\rremote: Compressing objects:  58% (68/117)\u001b[K\rremote: Compressing objects:  59% (70/117)\u001b[K\rremote: Compressing objects:  60% (71/117)\u001b[K\rremote: Compressing objects:  61% (72/117)\u001b[K\rremote: Compressing objects:  62% (73/117)\u001b[K\rremote: Compressing objects:  63% (74/117)\u001b[K\rremote: Compressing objects:  64% (75/117)\u001b[K\rremote: Compressing objects:  65% (77/117)\u001b[K\rremote: Compressing objects:  66% (78/117)\u001b[K\rremote: Compressing objects:  67% (79/117)\u001b[K\rremote: Compressing objects:  68% (80/117)\u001b[K\rremote: Compressing objects:  69% (81/117)\u001b[K\rremote: Compressing objects:  70% (82/117)\u001b[K\rremote: Compressing objects:  71% (84/117)\u001b[K\rremote: Compressing objects:  72% (85/117)\u001b[K\rremote: Compressing objects:  73% (86/117)\u001b[K\rremote: Compressing objects:  74% (87/117)\u001b[K\rremote: Compressing objects:  75% (88/117)\u001b[K\rremote: Compressing objects:  76% (89/117)\u001b[K\rremote: Compressing objects:  77% (91/117)\u001b[K\rremote: Compressing objects:  78% (92/117)\u001b[K\rremote: Compressing objects:  79% (93/117)\u001b[K\rremote: Compressing objects:  80% (94/117)\u001b[K\rremote: Compressing objects:  81% (95/117)\u001b[K\rremote: Compressing objects:  82% (96/117)\u001b[K\rremote: Compressing objects:  83% (98/117)\u001b[K\rremote: Compressing objects:  84% (99/117)\u001b[K\rremote: Compressing objects:  85% (100/117)\u001b[K\rremote: Compressing objects:  86% (101/117)\u001b[K\rremote: Compressing objects:  87% (102/117)\u001b[K\rremote: Compressing objects:  88% (103/117)\u001b[K\rremote: Compressing objects:  89% (105/117)\u001b[K\rremote: Compressing objects:  90% (106/117)\u001b[K\rremote: Compressing objects:  91% (107/117)\u001b[K\rremote: Compressing objects:  92% (108/117)\u001b[K\rremote: Compressing objects:  93% (109/117)\u001b[K\rremote: Compressing objects:  94% (110/117)\u001b[K\rremote: Compressing objects:  95% (112/117)\u001b[K\rremote: Compressing objects:  96% (113/117)\u001b[K\rremote: Compressing objects:  97% (114/117)\u001b[K\rremote: Compressing objects:  98% (115/117)\u001b[K\rremote: Compressing objects:  99% (116/117)\u001b[K\rremote: Compressing objects: 100% (117/117)\u001b[K\rremote: Compressing objects: 100% (117/117), done.\u001b[K\n",
            "Receiving objects:   0% (1/245)   \rReceiving objects:   1% (3/245)   \rReceiving objects:   2% (5/245)   \rReceiving objects:   3% (8/245)   \rReceiving objects:   4% (10/245)   \rReceiving objects:   5% (13/245)   \rReceiving objects:   6% (15/245)   \rReceiving objects:   7% (18/245)   \rReceiving objects:   8% (20/245)   \rReceiving objects:   9% (23/245)   \rReceiving objects:  10% (25/245)   \rReceiving objects:  11% (27/245)   \rReceiving objects:  12% (30/245)   \rReceiving objects:  13% (32/245)   \rReceiving objects:  14% (35/245)   \rReceiving objects:  15% (37/245)   \rReceiving objects:  16% (40/245)   \rReceiving objects:  17% (42/245)   \rReceiving objects:  18% (45/245)   \rReceiving objects:  19% (47/245)   \rReceiving objects:  20% (49/245)   \rReceiving objects:  21% (52/245)   \rReceiving objects:  22% (54/245)   \rReceiving objects:  23% (57/245)   \rReceiving objects:  24% (59/245)   \rReceiving objects:  25% (62/245)   \rReceiving objects:  26% (64/245)   \rReceiving objects:  27% (67/245)   \rReceiving objects:  28% (69/245)   \rReceiving objects:  29% (72/245)   \rReceiving objects:  30% (74/245)   \rReceiving objects:  31% (76/245)   \rReceiving objects:  32% (79/245)   \rReceiving objects:  33% (81/245)   \rReceiving objects:  34% (84/245)   \rReceiving objects:  35% (86/245)   \rReceiving objects:  36% (89/245)   \rReceiving objects:  37% (91/245)   \rReceiving objects:  38% (94/245)   \rReceiving objects:  39% (96/245)   \rReceiving objects:  40% (98/245)   \rReceiving objects:  41% (101/245)   \rReceiving objects:  42% (103/245)   \rReceiving objects:  43% (106/245)   \rReceiving objects:  44% (108/245)   \rReceiving objects:  45% (111/245)   \rReceiving objects:  46% (113/245)   \rReceiving objects:  47% (116/245)   \rReceiving objects:  48% (118/245)   \rReceiving objects:  49% (121/245)   \rReceiving objects:  50% (123/245)   \rReceiving objects:  51% (125/245)   \rReceiving objects:  52% (128/245)   \rReceiving objects:  53% (130/245)   \rReceiving objects:  54% (133/245)   \rReceiving objects:  55% (135/245)   \rremote: Total 245 (delta 124), reused 244 (delta 123), pack-reused 0\u001b[K\n",
            "Receiving objects:  56% (138/245)   \rReceiving objects:  57% (140/245)   \rReceiving objects:  58% (143/245)   \rReceiving objects:  59% (145/245)   \rReceiving objects:  60% (147/245)   \rReceiving objects:  61% (150/245)   \rReceiving objects:  62% (152/245)   \rReceiving objects:  63% (155/245)   \rReceiving objects:  64% (157/245)   \rReceiving objects:  65% (160/245)   \rReceiving objects:  66% (162/245)   \rReceiving objects:  67% (165/245)   \rReceiving objects:  68% (167/245)   \rReceiving objects:  69% (170/245)   \rReceiving objects:  70% (172/245)   \rReceiving objects:  71% (174/245)   \rReceiving objects:  72% (177/245)   \rReceiving objects:  73% (179/245)   \rReceiving objects:  74% (182/245)   \rReceiving objects:  75% (184/245)   \rReceiving objects:  76% (187/245)   \rReceiving objects:  77% (189/245)   \rReceiving objects:  78% (192/245)   \rReceiving objects:  79% (194/245)   \rReceiving objects:  80% (196/245)   \rReceiving objects:  81% (199/245)   \rReceiving objects:  82% (201/245)   \rReceiving objects:  83% (204/245)   \rReceiving objects:  84% (206/245)   \rReceiving objects:  85% (209/245)   \rReceiving objects:  86% (211/245)   \rReceiving objects:  87% (214/245)   \rReceiving objects:  88% (216/245)   \rReceiving objects:  89% (219/245)   \rReceiving objects:  90% (221/245)   \rReceiving objects:  91% (223/245)   \rReceiving objects:  92% (226/245)   \rReceiving objects:  93% (228/245)   \rReceiving objects:  94% (231/245)   \rReceiving objects:  95% (233/245)   \rReceiving objects:  96% (236/245)   \rReceiving objects:  97% (238/245)   \rReceiving objects:  98% (241/245)   \rReceiving objects:  99% (243/245)   \rReceiving objects: 100% (245/245)   \rReceiving objects: 100% (245/245), 11.81 MiB | 27.00 MiB/s, done.\n",
            "Resolving deltas:   0% (0/124)   \rResolving deltas:   3% (4/124)   \rResolving deltas:   6% (8/124)   \rResolving deltas:  13% (17/124)   \rResolving deltas:  17% (22/124)   \rResolving deltas:  49% (61/124)   \rResolving deltas:  51% (64/124)   \rResolving deltas:  53% (66/124)   \rResolving deltas:  54% (67/124)   \rResolving deltas:  55% (69/124)   \rResolving deltas:  56% (70/124)   \rResolving deltas:  58% (72/124)   \rResolving deltas:  60% (75/124)   \rResolving deltas:  63% (79/124)   \rResolving deltas:  67% (84/124)   \rResolving deltas:  79% (98/124)   \rResolving deltas:  84% (105/124)   \rResolving deltas:  86% (107/124)   \rResolving deltas:  99% (123/124)   \rResolving deltas: 100% (124/124)   \rResolving deltas: 100% (124/124), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFtQa80UUVlR",
        "colab_type": "code",
        "outputId": "c6a415de-53a3-4b85-b2be-c1325ba4006b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        }
      },
      "source": [
        "!wget https://s3-eu-west-1.amazonaws.com/densedepth/nyu.h5 -O ./DepthModel/nyu.h5"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-07 12:16:41--  https://s3-eu-west-1.amazonaws.com/densedepth/nyu.h5\n",
            "Resolving s3-eu-west-1.amazonaws.com (s3-eu-west-1.amazonaws.com)... 52.218.28.179\n",
            "Connecting to s3-eu-west-1.amazonaws.com (s3-eu-west-1.amazonaws.com)|52.218.28.179|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 172897376 (165M) [application/h5]\n",
            "Saving to: ‘./DepthModel/nyu.h5’\n",
            "\n",
            "./DepthModel/nyu.h5 100%[===================>] 164.89M  27.4MB/s    in 6.8s    \n",
            "\n",
            "2020-05-07 12:16:49 (24.4 MB/s) - ‘./DepthModel/nyu.h5’ saved [172897376/172897376]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyRBiZMrhvDv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir Depth_Part2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxDrX8GTX6Cc",
        "colab_type": "code",
        "outputId": "eba56e56-650e-429b-dcd1-0416667c67b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "%cd /content/DepthModel"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/DepthModel\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_naC6SNBYHto",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import notebook\n",
        "\n",
        "def DepthNorm(x, maxDepth):\n",
        "    return maxDepth / x\n",
        "\n",
        "def predict(model, images, minDepth=10, maxDepth=1000, batch_size=2):\n",
        "    # Support multiple RGBs, one RGB image, even grayscale \n",
        "    if len(images.shape) < 3: images = np.stack((images,images,images), axis=2)\n",
        "    if len(images.shape) < 4: images = images.reshape((1, images.shape[0], images.shape[1], images.shape[2]))\n",
        "    # Compute predictions\n",
        "    predictions = model.predict(images, batch_size=batch_size)\n",
        "    # Put in expected range\n",
        "    return np.clip(DepthNorm(predictions, maxDepth=maxDepth), minDepth, maxDepth) / maxDepth\n",
        "\n",
        "def scale_up(scale, images):\n",
        "    from skimage.transform import resize\n",
        "    scaled = []\n",
        "    \n",
        "    for i in range(len(images)):\n",
        "        img = images[i]\n",
        "        output_shape = (scale * img.shape[0], scale * img.shape[1])\n",
        "        scaled.append( resize(img, output_shape, order=1, preserve_range=True, mode='reflect', anti_aliasing=True ) )\n",
        "\n",
        "    return np.stack(scaled)\n",
        "\n",
        "def load_images(path,start,end):\n",
        "    loaded_images = []\n",
        "    for i in range(start,end):\n",
        "        x = np.clip(np.asarray(Image.open(f\"{path}fg-bg{str(i)}.jpg\" ).resize((448,448)), dtype=float) / 255, 0, 1)\n",
        "        loaded_images.append(x)\n",
        "    return np.stack(loaded_images, axis=0)\n",
        "\n",
        "def to_multichannel(i):\n",
        "    if i.shape[2] == 3: return i\n",
        "    i = i[:,:,0]\n",
        "    return np.stack((i,i,i), axis=2)\n",
        "        \n",
        "def display_images(outputs, inputs=None, gt=None, is_colormap=True, is_rescale=True, start = 1):\n",
        "    import matplotlib.pyplot as plt\n",
        "    import skimage\n",
        "    from skimage.transform import resize\n",
        "\n",
        "    plasma = plt.get_cmap('gray')\n",
        "\n",
        "    shape = (outputs[0].shape[0], outputs[0].shape[1], 3)\n",
        "    print(shape)\n",
        "    \n",
        "    #all_images = []\n",
        "    start = start\n",
        "    for i in notebook.tqdm(range(outputs.shape[0]),desc = f\"Loading from {start} images\") :\n",
        "    \n",
        "        if is_colormap:\n",
        "            rescaled = outputs[i][:,:,0]\n",
        "            if is_rescale:\n",
        "                rescaled = rescaled - np.min(rescaled)\n",
        "                rescaled = rescaled / np.max(rescaled)\n",
        "  \n",
        "            #plt.figure(figsize=(2.24,2.24),dpi=100)\n",
        "            matplotlib_image = plt.imshow(plasma(rescaled)[:,:,:3])\n",
        "            pil_image = Image.fromarray(np.uint8( ( matplotlib_image.get_array()*255))).convert(\"L\").resize((224,224))\n",
        "            pil_image.save(f\"/content/Depth_Part2/depth{str(start)}.jpg\")\n",
        "            plt.close() \n",
        "            start+=1\n",
        "\n",
        "            # plt.imsave(\"a.jpg\",plasma(rescaled)[:,:,:3])          \n",
        "\n",
        "        \n",
        "           \n",
        "\n",
        "def save_images(filename, outputs, inputs=None, gt=None, is_colormap=True, is_rescale=False):\n",
        "    montage =  display_images(outputs, inputs, is_colormap, is_rescale)\n",
        "    im = Image.fromarray(np.uint8(montage*255))\n",
        "    im.save(filename)\n",
        "\n",
        "def load_test_data(test_data_zip_file='nyu_test.zip'):\n",
        "    print('Loading test data...', end='')\n",
        "    import numpy as np\n",
        "    from data import extract_zip\n",
        "    data = extract_zip(test_data_zip_file)\n",
        "    from io import BytesIO\n",
        "    rgb = np.load(BytesIO(data['eigen_test_rgb.npy']))\n",
        "    depth = np.load(BytesIO(data['eigen_test_depth.npy']))\n",
        "    crop = np.load(BytesIO(data['eigen_test_crop.npy']))\n",
        "    print('Test data loaded.\\n')\n",
        "    return {'rgb':rgb, 'depth':depth, 'crop':crop}\n",
        "\n",
        "def compute_errors(gt, pred):\n",
        "    thresh = np.maximum((gt / pred), (pred / gt))\n",
        "    a1 = (thresh < 1.25   ).mean()\n",
        "    a2 = (thresh < 1.25 ** 2).mean()\n",
        "    a3 = (thresh < 1.25 ** 3).mean()\n",
        "    abs_rel = np.mean(np.abs(gt - pred) / gt)\n",
        "    rmse = (gt - pred) ** 2\n",
        "    rmse = np.sqrt(rmse.mean())\n",
        "    log_10 = (np.abs(np.log10(gt)-np.log10(pred))).mean()\n",
        "    return a1, a2, a3, abs_rel, rmse, log_10\n",
        "\n",
        "def evaluate(model, rgb, depth, crop, batch_size=6, verbose=False):\n",
        "    N = len(rgb)\n",
        "\n",
        "    bs = batch_size\n",
        "\n",
        "    predictions = []\n",
        "    testSetDepths = []\n",
        "    \n",
        "    for i in range(N//bs):    \n",
        "        x = rgb[(i)*bs:(i+1)*bs,:,:,:]\n",
        "        \n",
        "        # Compute results\n",
        "        true_y = depth[(i)*bs:(i+1)*bs,:,:]\n",
        "        pred_y = scale_up(2, predict(model, x/255, minDepth=10, maxDepth=1000, batch_size=bs)[:,:,:,0]) * 10.0\n",
        "        \n",
        "        # Test time augmentation: mirror image estimate\n",
        "        pred_y_flip = scale_up(2, predict(model, x[...,::-1,:]/255, minDepth=10, maxDepth=1000, batch_size=bs)[:,:,:,0]) * 10.0\n",
        "\n",
        "        # Crop based on Eigen et al. crop\n",
        "        true_y = true_y[:,crop[0]:crop[1]+1, crop[2]:crop[3]+1]\n",
        "        pred_y = pred_y[:,crop[0]:crop[1]+1, crop[2]:crop[3]+1]\n",
        "        pred_y_flip = pred_y_flip[:,crop[0]:crop[1]+1, crop[2]:crop[3]+1]\n",
        "        \n",
        "        # Compute errors per image in batch\n",
        "        for j in range(len(true_y)):\n",
        "            predictions.append(   (0.5 * pred_y[j]) + (0.5 * np.fliplr(pred_y_flip[j]))   )\n",
        "            testSetDepths.append(   true_y[j]   )\n",
        "\n",
        "    predictions = np.stack(predictions, axis=0)\n",
        "    testSetDepths = np.stack(testSetDepths, axis=0)\n",
        "\n",
        "    e = compute_errors(predictions, testSetDepths)\n",
        "\n",
        "    if verbose:\n",
        "        print(\"{:>10}, {:>10}, {:>10}, {:>10}, {:>10}, {:>10}\".format('a1', 'a2', 'a3', 'rel', 'rms', 'log_10'))\n",
        "        print(\"{:10.4f}, {:10.4f}, {:10.4f}, {:10.4f}, {:10.4f}, {:10.4f}\".format(e[0],e[1],e[2],e[3],e[4],e[5]))\n",
        "\n",
        "    return e"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6p0HzBL7UYdt",
        "colab_type": "code",
        "outputId": "e2febcb3-4136-45ce-b61d-c44cd10ff0cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "import os\n",
        "import glob\n",
        "import argparse\n",
        "import matplotlib\n",
        "\n",
        "# Keras / TensorFlow\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '5'\n",
        "from keras.models import load_model\n",
        "from layers import BilinearUpSampling2D\n",
        "#from utils import predict, load_images, display_images\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "\n",
        "# Custom object needed for inference and training\n",
        "custom_objects = {'BilinearUpSampling2D': BilinearUpSampling2D, 'depth_loss_function': None}\n",
        "\n",
        "print('Loading model...')\n",
        "\n",
        "# Load model into GPU / CPU\n",
        "model = load_model('nyu.h5', custom_objects=custom_objects, compile=False)\n",
        "\n",
        "print('\\nModel loaded ({0}).'.format(\"nyu.h5\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading model...\n",
            "\n",
            "Model loaded (nyu.h5).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YuRZQ9yM3GC_",
        "colab_type": "code",
        "outputId": "7c2a5d6e-73d9-49b4-9250-eaf8b9202403",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 149,
          "referenced_widgets": [
            "5725dc476d4a47cea846f55a56828755",
            "286f10453aec487aa8183f6ba949027e",
            "5b223155c6da4db5940842cef65b6649",
            "4a6e0881b71941e1badc66998f25388a",
            "d3b3b5bbf38e4e4da34271a098aab337",
            "161c83b6068b4d3483f755385479c2f1",
            "8eb2c34feead4c3d96eebab4223f716c",
            "595dc5e2d6af424f878267df886614dd"
          ]
        }
      },
      "source": [
        "%cd /content/DepthModel/\n",
        "# Input images\n",
        "# div = 50\n",
        "num = 150001\n",
        "End = 159500\n",
        "end_num =num+500\n",
        "# for  i in range((80000-13000)//div):\n",
        "# while end_num<=End+1:\n",
        "  \n",
        "  \n",
        "# print(num,end_num)\n",
        "inputs = load_images(path =\"/content/Overlay2/Fg-Bg/\",start=159501,end = 160001 )\n",
        "print('\\nLoaded ({0}) images of size {1}.'.format(inputs.shape[0], inputs.shape[1:]))\n",
        "# Compute results\n",
        "outputs = predict(model, inputs)\n",
        "# Display results\n",
        "display_images(outputs.copy(), inputs.copy(), start = 159501)\n",
        "# num = end_num\n",
        "# end_num = num+500\n",
        "print(\"done\")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/DepthModel\n",
            "\n",
            "Loaded (500) images of size (448, 448, 3).\n",
            "(224, 224, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5725dc476d4a47cea846f55a56828755",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Loading from 159501 images', max=500, style=ProgressStyle(des…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7wvfch93bdE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content/\n",
        "from zipfile import ZipFile \n",
        "import os \n",
        "  \n",
        "def get_all_file_paths(directory): \n",
        "  \n",
        "    # initializing empty file paths list \n",
        "    file_paths = [] \n",
        "  \n",
        "    # crawling through directory and subdirectories \n",
        "    for root, directories, files in os.walk(directory): \n",
        "        for filename in files: \n",
        "            # join the two strings in order to form the full filepath. \n",
        "            filepath = os.path.join(root, filename) \n",
        "            file_paths.append(filepath) \n",
        "  \n",
        "    # returning all file paths \n",
        "    return file_paths         \n",
        "  \n",
        "def main(): \n",
        "    # path to folder which needs to be zipped \n",
        "    directory = 'Depth_Part2'\n",
        "  \n",
        "    # calling function to get all file paths in the directory \n",
        "    file_paths = get_all_file_paths(directory) \n",
        "  \n",
        "    # printing the list of all files to be zipped \n",
        "    # print('Following files will be zipped:') \n",
        "    # for file_name in file_paths: \n",
        "    #     print(file_name) \n",
        "  \n",
        "    # writing files to a zipfile \n",
        "    with ZipFile('/content/gdrive/My Drive/Depth_Part2.zip','a') as zip: \n",
        "        # writing each file one by one \n",
        "        for file in file_paths: \n",
        "            zip.write(file) \n",
        "  \n",
        "    print('All files zipped successfully!')         \n",
        "  \n",
        "  \n",
        "\n",
        "main()\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}